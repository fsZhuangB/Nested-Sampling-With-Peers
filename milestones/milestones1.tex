
\setlength{\oddsidemargin}{1.5cm}
\setlength{\evensidemargin}{0cm}
\setlength{\topmargin}{1mm}
\setlength{\headheight}{1.36cm}
\setlength{\headsep}{1.00cm}
%\setlength{\textheight}{20.84cm}
\setlength{\textheight}{19cm}
\setlength{\textwidth}{14.5cm}
\setlength{\marginparsep}{1mm}
\setlength{\marginparwidth}{3cm}
\setlength{\footskip}{2.36cm}


\documentclass{article}
\usepackage{enumitem}
\usepackage{amssymb}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\checkmark$}

\title{Nested Sampling With Peers}

\author{
  Student: Feishuang Wang\\
  \texttt{fszhuangb@gmail.com}
  \and
  Supervisor: Dr Brendon James Brewer\\
  \texttt{bj.brewer@auckland.ac.nz}
}
\date{\today}


% milestones 1
\begin{document}
\maketitle

\section{Project description}
A nested sampling algorithm is a Bayesian approach to computing and comparing models and generating samples from posterior distributions. We introduce a general Monte Carlo method based on Nested Sampling, which name is Nested Sampling with peers. As an MCMC method, the least likelihood of the sample will be discarded and replaced. This method generates one particle above the threshold from the last iteration by querying the params from the server and updating it. We describe the new method over a test case named Spikeslab Problem and we will explore if it will have better or worse accuracy than the original MCMC-based nested sampling with the same computational overhead.
\section{Research question}
The research question is nested sampling with peers,  this method generates one particle above the threshold from the last iteration by querying the parameters from the server and updating them. 
\section{Proposed methodology}
The context of Bayesian Theorem shows that the likelihood function is $p(D|\theta)$, the prior distribution is 
$p(\theta)$, and the marginal likelihood function is $p(D)$, using the prior distribution and
likelihood function of the data D, we can obtain the posterior distribution of $\theta$:
\begin{equation}
    p(\theta|D) = \frac{\pi(\theta)d(\theta)}{p(D|\theta)}
\end{equation}
where the $p(\theta|D)$ is the posterior distribution.
In this dissertation, within the nested sampling paradigm, 
I will go through a specific problem named Spikeslab problem and build the original nested sampling based on the Metropolis algorithm on this specific problem,
and then calculate the MSE of different methods for comparison, where the implementation of nested sampling is done in C++, 
and the server is built using the python language and Flask web framework

\section{ Progress so far / work in progress}
So far, the project has been established, 
the server has been successfully set up and 
is currently verifying whether the nested sampling with peers method has improved compared with the traditional nested sampling method
\section{ Proposed timeline to completion of dissertation}
\begin{itemize}
    \item proprosed timeline to finish the dissertation"
  
    \begin{todolist}
      \item Building the basic programming environment:
      \begin{todolist}
        \item Operating system: Ubuntu 16.04, macOS 10.15.4
        \item Compiler: gcc 9.3.0
        \item Language: C++17, Python 3.8
        \item Editor: Visual Studio Code
      \end{todolist}
      \item Implement the basic nested sampling algorithm
      \item Calculating MSE function
      \item Implement the nested sampling with peers algorithm
      \begin{todolist}
        \item Implement the Flask web server
        \item Implement the updating particles from peers
      \end{todolist}
      \item[$\square$] Re-test the model by updating the database every iteration
      \item[$\square$] Comparing models
      \item[$\square$] Summarise the results
    \end{todolist}


  
  \end{itemize}

\end{document}